{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regression-EXERCISE.ipynb","provenance":[{"file_id":"1OWWg2skvgXyVSJBva9TUj7SPvR19Mdbl","timestamp":1574277905099}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"T9H4rAOJmyXO","colab_type":"text"},"source":["---\n","# Crash Course Python for Data Science â€” Predictive Modelling\n","---\n","# 01 - Regression modelling\n","---\n","<br>\n","\n","### 1. Experiment with Nearest Neighbor parameter\n","\n","Using the following code to load the same 10 training and test data points from the workshop."]},{"cell_type":"code","metadata":{"id":"CKsxHHzmmyXP","colab_type":"code","colab":{}},"source":["# Run this first!\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# plot tunning\n","plt.style.use(style='ggplot')\n","plt.rcParams['figure.figsize'] = (10, 6)\n","\n","columns = ['carat', 'cut', 'price']\n","\n","features = ['carat', 'cut']\n","target = 'price'\n","\n","train = pd.DataFrame(columns=columns, \n","        data=[[0.3, 'Ideal', 422],\n","        [0.31, 'Ideal', 489],\n","        [0.42, 'Premium', 737],\n","        [0.5, 'Ideal', 1415],\n","        [0.51, 'Premium', 1177],\n","        [0.7, 'Fair', 1865],\n","        [0.73, 'Fair', 2351],\n","        [1.01, 'Good', 3768],\n","        [1.18, 'Very Good', 3965],\n","        [1.18, 'Ideal', 4838]])\n","\n","test  = pd.DataFrame(columns=columns, \n","        data=[[0.3, 'Ideal', 432],\n","        [0.34, 'Ideal', 687],\n","        [0.37, 'Premium', 1124],\n","        [0.4, 'Good', 720],\n","        [0.51, 'Ideal', 1397],\n","        [0.51, 'Very Good', 1284],\n","        [0.59, 'Ideal', 1437],\n","        [0.7, 'Ideal', 3419],\n","        [0.9, 'Premium', 3484],\n","        [0.9, 'Fair', 2964]])\n","\n","cut_ranks = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n","train.cut = train.cut.map(cut_ranks)\n","test.cut = test.cut.map(cut_ranks)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDQvM-OieVNd","colab_type":"text"},"source":["Then, train a `KNeighborsRegressor` model with `n_neighbors=1`.\n","\n","Use both `carat` and `cut` features.\n","\n","Calculate the mean absolute error on the training data and on the test data."]},{"cell_type":"code","metadata":{"id":"_3trzLnhdc6b","colab_type":"code","colab":{}},"source":["# Step 1. Create instance of the model \n","\n","### YOUR CODE GOES HERE ###\n","\n","# Step 2. Train the algorithm\n","\n","### YOUR CODE GOES HERE ###\n","\n","# Step 3. Make predictions\n","\n","### YOUR CODE GOES HERE ###\n","\n","# Step 4. Evaluate the model \n","\n","### YOUR CODE GOES HERE ###\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MrRasT_myXT","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Create instance of the model\n","KNNmodel = KNeighborsRegressor(n_neighbors=1)\n","\n","#training the algorithm\n","KNNmodel.fit(train[features], train[target])\n","\n","# Making predictions \n","y_true_train = train[target]\n","y_true_test = test[target]\n","training_preds = KNNmodel.predict(train[features])\n","val_preds = KNNmodel.predict(test[features])\n","\n","# Model evaluation\n","print(\"\\nTraining AMSE:\", round(mean_absolute_error(y_true_train, training_preds),4))\n","print(\"\\nValidation AMSE:\", round(mean_absolute_error(y_true_test, val_preds),4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQQveVK9myXV","colab_type":"text"},"source":["How does the train error and test error compare to the previous `KNeighborsRegressor` model from the lesson? (The previous model used `n_neighbors=2` and only the `carat` feature.)\n","\n","Is this new model overfitting or underfitting? Why do you think this is happening here? \n","\n"]},{"cell_type":"markdown","metadata":{"id":"zQJDW1-QmyXW","colab_type":"text"},"source":["### 2. More data, two features, linear regression\n","\n","Use the following code to load data for diamonds under $5,000, and split the data into train and test sets. The training data has almost 30,000 rows, and the test data has almost 10,000 rows."]},{"cell_type":"code","metadata":{"id":"IDXEn8lvmyXW","colab_type":"code","colab":{}},"source":["import seaborn as sns\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","\n","df = sns.load_dataset('diamonds')\n","df = df[df.price < 5000]\n","train, test = train_test_split(df.copy(), random_state=0)\n","train.shape, test.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyStJOe0XY-n","colab_type":"code","colab":{}},"source":["# Run this to check the dataset loaded and looks ok\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWluyktRbHNr","colab_type":"code","colab":{}},"source":["# Run this to encode the ordinal features as numbers\n","cut_ranks = {'Fair': 1, 'Good': 2, 'Very Good': 3, 'Premium': 4, 'Ideal': 5}\n","train.cut = train.cut.map(cut_ranks)\n","target = test.cut = test.cut.map(cut_ranks)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1VZ7PH6nmyXZ","colab_type":"text"},"source":["Then, train a Linear Regression model with the `carat` and `cut` features. Calculate the mean absolute error on the training data and on the test data."]},{"cell_type":"code","metadata":{"id":"XCTsEqZtmyXZ","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","target = 'price'\n","features = ['carat', 'cut']\n","\n","# Create instance of the model\n","linearmodel = LinearRegression()\n","\n","#training the algorithm\n","linearmodel.fit(train[features], train[target])\n","\n","# Making predictions \n","y_true_train = train[target]\n","y_true_test = test[target]\n","training_preds = linearmodel.predict(train[features])\n","val_preds = linearmodel.predict(test[features])\n","\n","# Evaluation\n","print(\"\\nTraining AMSE:\", round(mean_absolute_error(y_true_train, training_preds),4))\n","print(\"\\nValidation AMSE:\", round(mean_absolute_error(y_true_test, val_preds),4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4jLEcukVmyXb","colab_type":"text"},"source":["Use this model to predict the price of a half carat diamond with \"very good\" cut"]},{"cell_type":"code","metadata":{"id":"tzNj9J3lgfBH","colab_type":"code","colab":{}},"source":["### YOUR CODE GOES HERE ###"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1pDzeLZmyXb","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","linearmodel.predict([[0.5, 3]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eB-7wzRjmyXe","colab_type":"text"},"source":["### 3. More data, more features, any model"]},{"cell_type":"markdown","metadata":{"id":"OCauk9z2myXf","colab_type":"text"},"source":["You choose what features and model type to use! Try to get a better mean absolute error on the test set than your model from the last question."]},{"cell_type":"markdown","metadata":{"id":"nWVpkz8dmyXf","colab_type":"text"},"source":["Refer to [this documentation](https://ggplot2.tidyverse.org/reference/diamonds.html) for more explanation of the features.\n","\n","Besides `cut`, there are two more ordinal features, which you'd need to encode as numbers if you want to use in your model: `color` and `clarity`."]},{"cell_type":"code","metadata":{"id":"54K95PyEmyXf","colab_type":"code","colab":{}},"source":["# Run this to see the description of color and clarity features\n","train.describe(include=['object'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arYOlKNNg93Q","colab_type":"text"},"source":["### Below I've written an example solution using K'Nearest, Linear Regression and a regression algorithm we didn't cover in the crash course, known as XGBoost. I strongly encourage you to come up with **your own** solution before looking at mine!"]},{"cell_type":"code","metadata":{"id":"aM2ksd9Lh5Tb","colab_type":"code","colab":{}},"source":["# Add as many extra cells as you need. \n","\n","\n","### YOUR CODE GOES HERE ###\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6aaWVRqWolz","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Encoding clarity as numbers\n","\n","clarity_rank = {\"IF\":0,\"VVS1\":1, \"VVS2\":2,\"VS1\":3, \"VS2\":4,\"SI1\":5, \"SI2\":6, \"I1\":7}\n","train.clarity = train.clarity.map(clarity_rank) \n","test.clarity = test.clarity.map(clarity_rank) \n","\n","color_rank = {\"J\":7, \"I\":6, \"H\":5, \"G\":4, \"F\":3, \"E\":2, \"D\":1 }\n","train.color = train.color.map(color_rank)\n","test.color = test.color.map(color_rank)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKyr7eWUWqMd","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# checking the changes are there and every\n","# feature of the dataset is numerical \n","\n","train.head()\n","test.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wAoZ1plQYVc","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# K-Nearest\n","\n","# Create instance of the model\n","KNNmodel = KNeighborsRegressor(n_neighbors=1)\n","\n","#training the algorithm\n","KNNmodel.fit(train[features], train[target])\n","\n","# Making predictions \n","y_true_train = train[target]\n","y_true_test = test[target]\n","training_preds = KNNmodel.predict(train[features])\n","val_preds = KNNmodel.predict(test[features])\n","\n","print(\"\\nTraining AMSE:\", round(mean_absolute_error(y_true_train, training_preds),4))\n","print(\"\\nValidation AMSE:\", round(mean_absolute_error(y_true_test, val_preds),4))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUiQCTdQmyXi","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Linear Regression\n","\n","features = ['color','clarity']\n","target = ['price']\n","\n","# Create instance of the model\n","linearmodel = LinearRegression()\n","\n","#training the algorithm\n","linearmodel.fit(train[features], train[target])\n","\n","# Making predictions \n","y_true_train = train[target]\n","y_true_test = test[target]\n","training_preds = linearmodel.predict(train[features])\n","val_preds = linearmodel.predict(test[features])\n","\n","print(\"\\nTraining AMSE:\", round(mean_absolute_error(y_true_train, training_preds),4))\n","print(\"\\nValidation AMSE:\", round(mean_absolute_error(y_true_test, val_preds),4))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_E1mQ7nYYS1","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","import xgboost as xgb\n","from xgboost import plot_importance\n","\n","# XGBoost \n","\n","# Create instance of the model\n","xgb_reg = xgb.XGBRegressor()\n","\n","#training the algorithm\n","xgb_reg.fit(train[features], train[target])\n","\n","# Making predictions \n","y_true_train = train[target]\n","y_true_test = test[target]\n","training_preds = xgb_reg.predict(train[features])\n","val_preds = xgb_reg.predict(test[features])\n","\n","print(\"\\nTraining AMSE:\", round(mean_absolute_error(y_true_train, training_preds),4))\n","print(\"\\nValidation AMSE:\", round(mean_absolute_error(y_true_test, val_preds),4))"],"execution_count":0,"outputs":[]}]}