{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification-EXERCISE.ipynb","provenance":[{"file_id":"14GTb5Zq-8Xif7DmPTcRfxawvpA1N-zwU","timestamp":1574347557177}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lOH73mi0Wc3q","colab_type":"text"},"source":["---\n","# Crash Course Python for Data Science — Predictive Modelling\n","---\n","# 02 - Classification modelling\n","---\n","##STOP! BEFORE GOING ANY FURTHER...  \n","\n","1. Click \"File\" at the top.\n","2. Then, \"Save a Copy in Drive.\"\n","3. Change the file name to something else, so you can differenciate it from the workshop notes. For example, put your name at the beggining: \"Grace_Classification-EXERCISE\".  \n","\n","Now you have a copy of this notebook in your Drive account. This is the copy you'll edit and save for your own archives. You can come back to it as many times as you like to practice again! Be sure to do this for ***every*** exercise!\n","\n","Remember, this exercises are open book, open neighbour, open everything! Try to do them on your own before looking at the solution samples. Join the slack channel to ask your questions. I will be in the channel too!\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"EQ6Yq0xkWc3r","colab_type":"text"},"source":["## Exercise\n","\n","Run this cell to load the Titanic data:"]},{"cell_type":"code","metadata":{"id":"MsZf-QBJWc3s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5481d72f-a05a-4736-f626-9c9dd5294960","executionInfo":{"status":"ok","timestamp":1578674896074,"user_tz":0,"elapsed":2000,"user":{"displayName":"Graciela Carrillo","photoUrl":"","userId":"06628992144787984230"}}},"source":["# linear algebra\n","import numpy as np \n","\n","# data processing\n","import pandas as pd \n","\n","# data visualization\n","import seaborn as sns\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from matplotlib import style\n","\n","# Algorithms\n","from sklearn import linear_model\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression       \n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Evaluation\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score \n","\n","# Set plot preference\n","plt.style.use(style='ggplot')\n","plt.rcParams['figure.figsize'] = (10, 6)\n","\n","# time\n","import time\n","\n","print('Libraries imported.')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Libraries imported.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWnyTrASWc3v","colab_type":"text"},"source":["Then, train a [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba), [Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), or [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model. Use any features and parameters you want. \n","\n","Try to get better than 78.0% accuracy on the test set! (This is not required, but encouraged.)\n","\n","Do refer to the lecture notebook — but try not to copy-paste.\n","\n","> You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons. —*[Learn Python the Hard Way](https://learnpythonthehardway.org/book/intro.html)*\n","\n","After this, you may want to try [Kaggle's Titanic challenge](https://www.kaggle.com/c/titanic)!\n","\n","Again, I've written an example solution covereing everything, from exploratory data analysis (cleaning data and all that) to model evaluation for you to see the whole process. I strongly encourage you to come up with your own solution before looking at mine!"]},{"cell_type":"code","metadata":{"id":"FGT0WHTfWc3v","colab_type":"code","colab":{}},"source":["# Run this to split your data into train and test\n","\n","train, test = train_test_split(sns.load_dataset('titanic').drop(columns=['alive']), random_state=0)\n","target = 'survived'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3LGBR2refLc","colab_type":"text"},"source":["## 1. Exploratory Data Analysis\n"]},{"cell_type":"code","metadata":{"id":"LYxU3-qcfXcy","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","train.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZ_UW0rhRIHj","colab_type":"text"},"source":["#### Feature description\n","\n","- `survived`:    Survival  \n","- `pclass`:    Ticket class     \n","- `sex`:    Sex     \n","- `age`:    Age in years     \n","- `sibsp`:    # of siblings / spouses aboard the Titanic     \n","- `parch`:    # of parents / children aboard the Titanic         \n","- `fare`:    Passenger fare     \n","- `deck`:    Deck    \n","- `embarked`: Port of Embarkation\n","- `embark_town`: Town of Embarkation\n","- `alone`: if person was travelling alone or not\n","- `who`: male or female\n","- `adult_male`: If person was male or not"]},{"cell_type":"code","metadata":{"id":"adIhGUOneaiE","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","train.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5Y4-4wWflft","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUV3n5ULfn55","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Missing values \n","\n","total = train.isnull().sum().sort_values(ascending=False)\n","percent_1 = train.isnull().sum()/train.isnull().count()*100\n","percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n","missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n","missing_data.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4AzaAC_7gLAB","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train.columns.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RsakH2JZgXRK","colab_type":"text"},"source":["### `age` vs `sex`"]},{"cell_type":"code","metadata":{"id":"MKi1cqypgZUn","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","survived = 'survived'\n","not_survived = 'not survived'\n","fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n","women = train[train['sex']=='female']\n","men = train[train['sex']=='male']\n","\n","#Female survived/not survided\n","ax = sns.distplot(women[women['survived']==1].age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n","ax = sns.distplot(women[women['survived']==0].age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n","ax.legend()\n","ax.set_title('Female')\n","\n","#Male survived/not survived\n","ax = sns.distplot(men[men['survived']==1].age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n","ax = sns.distplot(men[men['survived']==0].age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n","ax.legend()\n","_ = ax.set_title('Male')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywTmz3SHSsAa","colab_type":"text"},"source":["Seems pretty clear that `sex` has to do with survival probability"]},{"cell_type":"markdown","metadata":{"id":"Vo8j_xGQiD1K","colab_type":"text"},"source":["### `embarked`, `pclass` and `sex`"]},{"cell_type":"code","metadata":{"id":"UxYnKp2tiLvQ","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","FacetGrid = sns.FacetGrid(train, row='embarked', size=4.5, aspect=1.6)\n","FacetGrid.map(sns.pointplot, 'pclass', 'survived', 'sex', palette=None,  order=None, hue_order=None )\n","FacetGrid.add_legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bF8nlsjzjAwW","colab_type":"text"},"source":["`embarked` seems correlated with survival depending on gender, as `pclass`"]},{"cell_type":"code","metadata":{"id":"cyFquvWQjSBg","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","sns.barplot(x='pclass', y='survived', data=train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNIIVvuxjZpw","colab_type":"text"},"source":["`pclass` appears to be contributing to survival"]},{"cell_type":"code","metadata":{"id":"_uhQdqxLjdPj","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","grid = sns.FacetGrid(train, col='survived', row='pclass', size=2.2, aspect=1.6)\n","grid.map(plt.hist, 'age', alpha=.5, bins=20)\n","grid.add_legend();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dyVEEtNVjr-3","colab_type":"text"},"source":["Assumption about `pclass` 1 contributing ti survival appears true. There seems to be a low probability of persons in `pclass` 3 not surviving."]},{"cell_type":"code","metadata":{"id":"un95wh_HTBqb","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","survived = 'survived'\n","not_survived = 'not survived'\n","fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n","alone = train[train['alone']==True]\n","not_alone = train[train['alone']==False]\n","\n","# Alone survived/not survided\n","ax = sns.distplot(alone[alone['survived']==1].age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n","ax = sns.distplot(alone[alone['survived']==0].age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n","ax.legend()\n","ax.set_title('Alone')\n","\n","# Not alone survived/not survived\n","ax = sns.distplot(not_alone[not_alone['survived']==1].age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n","ax = sns.distplot(not_alone[not_alone['survived']==0].age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n","ax.legend()\n","_ = ax.set_title('Not alone')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xI3FSDGSUcEh","colab_type":"text"},"source":["Seems like younger people travelling alone have a higher probability or survival, whereas travelling not alone is more relatively equally distributed between age groups."]},{"cell_type":"markdown","metadata":{"id":"L-g85xBfkI4N","colab_type":"text"},"source":["## 2. Data cleaning"]},{"cell_type":"markdown","metadata":{"id":"79QdsD64EnT6","colab_type":"text"},"source":["#### Drop `class`, `adult_male` and `who` as they are repetitive. Also dropping `sibsp` and `parch`, as `alone` already accounts for travelling alone or with family/friends. "]},{"cell_type":"code","metadata":{"id":"Ey34RGYfEkNb","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train = train.drop(['class', 'adult_male', 'who', 'sibsp', 'parch'], axis=1)\n","test = test.drop(['class', 'adult_male', 'who', 'sibsp', 'parch'], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLjevjTzmtqA","colab_type":"text"},"source":["### Missing values `deck`"]},{"cell_type":"code","metadata":{"id":"yOP2frgimwRc","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train['deck'].describe()  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhqXWySCpot0","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# 512 missing values, we'll just replace with 0\n","print('deck has', train['deck'].isna().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yamg_muVnfl7","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","deck = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H':0}\n","data = [train, test]\n","\n","# fill NaN values with H first, then fill values with numerical data\n","for dataset in data:\n","  dataset['deck'] = dataset['deck'].cat.add_categories('H').fillna('H')\n","  dataset['deck'] = dataset['deck'].map(deck)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmE61ulK0tNa","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","print('train `deck` has', train['deck'].isna().sum(), 'missing values')\n","print('test `deck` has', test['deck'].isna().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aW4CJVXkrix","colab_type":"text"},"source":["### Missing values `age`"]},{"cell_type":"code","metadata":{"id":"i5RZx75G70oR","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","print('age has', train['age'].isna().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s81mk-gOkLmm","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","data = [train, test]\n","\n","for dataset in data:\n","    mean = train[\"age\"].mean()\n","    std = test[\"age\"].std()\n","    is_null = dataset[\"age\"].isnull().sum()\n","\n","    # compute random numbers between the mean, std and is_null\n","    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n","\n","    # fill NaN values in age column with random values generated\n","    age_slice = dataset[\"age\"].copy()\n","    age_slice[np.isnan(age_slice)] = rand_age\n","    dataset[\"age\"] = age_slice\n","    dataset[\"age\"] = dataset[\"age\"].astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxQvSlgX7bXx","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","print('train `age` has', train['age'].isna().sum(), 'missing values')\n","print('test `age` has', test['age'].isna().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"npdO5EFtmEkc","colab_type":"text"},"source":["### Missing values `embarked` and `embark_town`"]},{"cell_type":"code","metadata":{"id":"BlicX6zH8CCG","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","print('train `embarked` has', train['embarked'].isnull().sum(), 'missing values')\n","print('test `embarked` has', test['embarked'].isnull().sum(), 'missing values')\n","print('train `embarked_town` has', train['embark_town'].isnull().sum(), 'missing values')\n","print('test `embarked_town` has', test['embark_town'].isnull().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALjGVym5l8sD","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Just 2 missings in train set so will fill in with mode\n","train['embarked'].describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAF7tegu6nsP","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train['embark_town'].describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_nKKa38mQug","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","common_value = 'S'\n","common_town = 'Southampton'\n","data = [train]\n","\n","for dataset in data:\n","    dataset['embarked'] = dataset['embarked'].fillna(common_value)\n","    dataset['embark_town'] = dataset['embark_town'].fillna(common_town)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYtBi51e6-yi","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# double check\n","print('train `embarked` has', train['embarked'].isnull().sum(), 'missing values')\n","print('test `embarked` has', test['embarked'].isnull().sum(), 'missing values')\n","print('train `embarked_town` has', train['embark_town'].isnull().sum(), 'missing values')\n","print('test `embarked_town` has', test['embark_town'].isnull().sum(), 'missing values')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M1UxeIVw8KPS","colab_type":"text"},"source":["## 3. Preparing data for modelling"]},{"cell_type":"code","metadata":{"id":"tXT_SuKD8XjH","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RjacQSxz92Fm","colab_type":"text"},"source":["#### `fare` from `float64` to `int64`"]},{"cell_type":"code","metadata":{"id":"HVPpCabf-AeA","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","data = [train, test]\n","\n","for dataset in data:\n","    dataset['fare'] = dataset['fare'].fillna(0)\n","    dataset['fare'] = dataset['fare'].astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LHT49XaQ-Y0x","colab_type":"text"},"source":["#### `sex` to numeric\n"]},{"cell_type":"code","metadata":{"id":"TKKV0l8kBRy9","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","sex = {\"male\": 0, \"female\": 1}\n","data = [train, test]\n","\n","for dataset in data:\n","    dataset['sex'] = dataset['sex'].map(sex)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdftyXGVBjgH","colab_type":"text"},"source":["#### `embarked` to numeric"]},{"cell_type":"code","metadata":{"id":"bl9r_c2FBmG3","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n","data = [train, test]\n","\n","for dataset in data:\n","    dataset['embarked'] = dataset['embarked'].map(ports)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Liz3CN_jFIlx","colab_type":"text"},"source":["### `alone` from boolean to numeric"]},{"cell_type":"code","metadata":{"id":"csHjkj-lFOjD","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","data = [train, test]\n","for dataset in data:\n","    dataset['alone'] = dataset['alone'].astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pXIJhyXDe52","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train.info()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSXWYmnYDlIp","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","train.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kL0eRYA8Gsk8","colab_type":"text"},"source":["### Getting dummies for categorical `deck` and `embark_town`"]},{"cell_type":"code","metadata":{"id":"kKE2V3ovGzpN","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","train = pd.get_dummies(train)\n","train.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5Cps7emHQQy","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","test = pd.get_dummies(test)\n","test.head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"96U1wP4RPmwe","colab_type":"text"},"source":["### Multicollinearity"]},{"cell_type":"code","metadata":{"id":"LIKGoXpJPmPN","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","def multi_collinearity_heatmap(df, figsize=(11,9)):\n","    \n","    \"\"\"\n","    Creates a heatmap of correlations between features in the df. \n","    A figure size can optionally be set.\n","    \"\"\"\n","    \n","    # Set the style of the visualization\n","    sns.set(style=\"white\")\n","\n","    # Create a covariance matrix\n","    corr = df.corr()\n","\n","    # Generate a mask the size of our covariance matrix\n","    mask = np.zeros_like(corr, dtype=np.bool)\n","    mask[np.triu_indices_from(mask)] = True\n","\n","    # Set up the matplotlib figure\n","    f, ax = plt.subplots(figsize=figsize)\n","\n","    # Generate a custom diverging colormap\n","    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n","\n","    # Draw the heatmap with the mask and correct aspect ratio\n","    sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, vmax=corr[corr != 1.0].max().max());"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwiFzsjgPqYf","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","multi_collinearity_heatmap(train, figsize=(10,10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FruBAfK3QvIW","colab_type":"text"},"source":["Areas of multi-collinearity::\n","\n","`embark_town_Queenston` and `embarked_Cherbourg` show a strong positive correlation with `embarked`, whistle `embark_town_Southampton` is strongly negatively correlated with `embarked`. This suggests that including `embark_town` only as a feature should be enough to control for the influence of place of embarkment.\n","\n","`deck_0` which is our `NaN` values, and `pclass` are perfectly positively correlated and negatively correlated with `fare`. This could mean different things. Perhaps is because deck numbers are correlated with ticket class and people without a ticket were all from certain class. Thus, dropping `deck_0` should be ok, as it is being taken into account by `pclass`. \n","\n","As expected, `sex` and `survived` also show strong positive correlation. \n","\n","Unsurprisingly, `fare` and `pclass` are strongly negatively correlated, so one will be dropped."]},{"cell_type":"code","metadata":{"id":"IIdy61UMaF9-","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","to_drop = ['embarked', 'fare', 'deck_0']\n","data = [train, test]\n","\n","for dataset in data:\n","  to_drop.extend(list(dataset.columns[dataset.columns.str.endswith('nan')]))\n","  dataset.drop(to_drop, axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-gFsMOHatB6","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Final assessment multicollinearity\n","multi_collinearity_heatmap(train, figsize=(10,10))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZaFcepzGJnRs","colab_type":"text"},"source":["### Feature scaling"]},{"cell_type":"markdown","metadata":{"id":"TNtwDLvSLde1","colab_type":"text"},"source":["Finally, predictive features `X` and the target feature `y` can be separated, and `X` will be scaled with `StandardScaler` from `sklearn`."]},{"cell_type":"code","metadata":{"id":"jzYzfFE9MQ6F","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Separating X and y\n","X_train  = train.drop(target, axis=1)\n","Y_train = train[target]\n","\n","X_test = test.drop(target, axis=1)\n","Y_test = test[target]\n","\n","# Scaling\n","scaler = StandardScaler()\n","X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=list(X_train.columns))\n","X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=list(X_test.columns))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kf0EMEk1C-aW","colab_type":"text"},"source":["## 4. Building a Machine Learning Model"]},{"cell_type":"markdown","metadata":{"id":"ymRtpTkXOPk7","colab_type":"text"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"zfsZSZs3DAqS","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","rf_start = time.time()\n","\n","# Create instance of the model\n","rf = RandomForestClassifier(n_estimators=100)\n","\n","# training the algorithm\n","rf.fit(X_train, Y_train)\n","\n","# making predictions\n","Y_pred = rf.predict(X_test)\n","\n","rf_end = time.time()\n","\n","print(f\"Time taken to run: {round((rf_end - rf_start)/60,1)} minutes\")\n","\n","# Check the predictions against the actual values:\n","\n","print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n","print('Classification report:', classification_report(Y_test, Y_pred))\n","print('Acuracy:', accuracy_score(Y_test, Y_pred))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TasZE7k1jDGV","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","\n","# Feature importance\n","rf_importance = pd.DataFrame(rf.feature_importances_, columns=['importance'], index = X_train.columns)\n","\n","# Plotting feature importances\n","plt.figure(figsize=(5,5))\n","plt.barh(rf_importance.index, rf_importance.importance, align='center') \n","plt.title(\"Feature importances in the Random Forest model\", fontsize=14)\n","plt.xlabel(\"Feature importance\")\n","plt.margins(y=0.01)\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-5QRDKMoe6d","colab_type":"text"},"source":["## 5. Conclusion\n"]},{"cell_type":"markdown","metadata":{"id":"StIZFOdpoB4g","colab_type":"text"},"source":["As expected, `sex` and `age` are the main features by far, with a model accuracy of 79.37%, which could be improved by doing some hyper-parameter tunning.\n"]}]}