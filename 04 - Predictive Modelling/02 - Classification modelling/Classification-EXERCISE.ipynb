{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification-EXERCISE.ipynb","provenance":[{"file_id":"14GTb5Zq-8Xif7DmPTcRfxawvpA1N-zwU","timestamp":1574347557177}],"collapsed_sections":[]},"kernelspec":{"name":"python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d","display_name":"Python 3.9.0 64-bit"},"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"}}},"cells":[{"cell_type":"markdown","metadata":{"id":"lOH73mi0Wc3q","colab_type":"text"},"source":["---\n","# Crash Course Python for Data Science — Predictive Modelling\n","---\n","# 02 - Classification modelling\n","---\n","## STOP! BEFORE GOING ANY FURTHER...  \n","\n","Remember, this exercises are open book, open neighbour, open everything! Try to do them on your own before looking at the solution samples.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"EQ6Yq0xkWc3r","colab_type":"text"},"source":["## Exercise\n","\n","Run this cell to load the Titanic data:"]},{"cell_type":"code","metadata":{"id":"MsZf-QBJWc3s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"5481d72f-a05a-4736-f626-9c9dd5294960","executionInfo":{"status":"ok","timestamp":1578674896074,"user_tz":0,"elapsed":2000,"user":{"displayName":"Graciela Carrillo","photoUrl":"","userId":"06628992144787984230"}}},"source":["# linear algebra\n","import numpy as np \n","\n","# data processing\n","import pandas as pd \n","\n","# data visualization\n","import seaborn as sns\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","from matplotlib import style\n","\n","# Algorithms\n","from sklearn import linear_model\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression       \n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Evaluation\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score \n","\n","# Set plot preference\n","plt.style.use(style='ggplot')\n","plt.rcParams['figure.figsize'] = (10, 6)\n","\n","# time\n","import time\n","\n","print('Libraries imported.')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Libraries imported.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BWnyTrASWc3v","colab_type":"text"},"source":["Then, train a [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba), [Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), or [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model. Use any features and parameters you want. \n","\n","Try to get better than 78.0% accuracy on the test set! (This is not required, but encouraged.)\n","\n","Do refer to the lecture notebook — but try not to copy-paste.\n","\n","> You must type each of these exercises in, manually. If you copy and paste, you might as well not even do them. The point of these exercises is to train your hands, your brain, and your mind in how to read, write, and see code. If you copy-paste, you are cheating yourself out of the effectiveness of the lessons. —*[Learn Python the Hard Way](https://learnpythonthehardway.org/book/intro.html)*\n","\n","After this, you may want to try [Kaggle's Titanic challenge](https://www.kaggle.com/c/titanic)!\n","\n","Again, I've written an example solution covereing everything, from exploratory data analysis (cleaning data and all that) to model evaluation for you to see the whole process. I strongly encourage you to come up with your own solution before looking at mine!"]},{"cell_type":"code","metadata":{"id":"FGT0WHTfWc3v","colab_type":"code","colab":{}},"source":["# Run this to split your data into train and test\n","\n","train, test = train_test_split(sns.load_dataset('titanic').drop(columns=['alive']), random_state=0)\n","target = 'survived'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3LGBR2refLc","colab_type":"text"},"source":["## 1. Exploratory Data Analysis\n"]},{"cell_type":"code","metadata":{"id":"LYxU3-qcfXcy","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Double click here for a sample solution\n","train.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZ_UW0rhRIHj","colab_type":"text"},"source":["#### Feature description\n","\n","- `survived`:    Survival  \n","- `pclass`:    Ticket class     \n","- `sex`:    Sex     \n","- `age`:    Age in years     \n","- `sibsp`:    # of siblings / spouses aboard the Titanic     \n","- `parch`:    # of parents / children aboard the Titanic         \n","- `fare`:    Passenger fare     \n","- `deck`:    Deck    \n","- `embarked`: Port of Embarkation\n","- `embark_town`: Town of Embarkation\n","- `alone`: if person was travelling alone or not\n","- `who`: male or female\n","- `adult_male`: If person was male or not"]},{"cell_type":"code","metadata":{"id":"adIhGUOneaiE","colab_type":"code","cellView":"form","colab":{}},"source":["# Your Code Goes Here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RsakH2JZgXRK","colab_type":"text"},"source":["### `age` vs `sex`"]},{"cell_type":"code","metadata":{"id":"MKi1cqypgZUn","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywTmz3SHSsAa","colab_type":"text"},"source":["Seems pretty clear that `sex` has to do with survival probability"]},{"cell_type":"markdown","metadata":{"id":"Vo8j_xGQiD1K","colab_type":"text"},"source":["### `embarked`, `pclass` and `sex`"]},{"cell_type":"code","metadata":{"id":"UxYnKp2tiLvQ","colab_type":"code","cellView":"form","colab":{}},"source":["# your code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bF8nlsjzjAwW","colab_type":"text"},"source":["`embarked` seems correlated with survival depending on gender, as `pclass`"]},{"cell_type":"code","metadata":{"id":"cyFquvWQjSBg","colab_type":"code","cellView":"form","colab":{}},"source":["# your code goes here\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNIIVvuxjZpw","colab_type":"text"},"source":["`pclass` appears to be contributing to survival"]},{"cell_type":"code","metadata":{"id":"_uhQdqxLjdPj","colab_type":"code","cellView":"form","colab":{}},"source":["# your code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dyVEEtNVjr-3","colab_type":"text"},"source":["Assumption about `pclass` 1 contributing ti survival appears true. There seems to be a low probability of persons in `pclass` 3 not surviving."]},{"cell_type":"code","metadata":{"id":"un95wh_HTBqb","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xI3FSDGSUcEh","colab_type":"text"},"source":["Seems like younger people travelling alone have a higher probability or survival, whereas travelling not alone is more relatively equally distributed between age groups."]},{"cell_type":"markdown","metadata":{"id":"L-g85xBfkI4N","colab_type":"text"},"source":["## 2. Data cleaning"]},{"cell_type":"markdown","metadata":{"id":"79QdsD64EnT6","colab_type":"text"},"source":["#### Drop `class`, `adult_male` and `who` as they are repetitive. Also dropping `sibsp` and `parch`, as `alone` already accounts for travelling alone or with family/friends. "]},{"cell_type":"code","metadata":{"id":"Ey34RGYfEkNb","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLjevjTzmtqA","colab_type":"text"},"source":["### Missing values `deck`"]},{"cell_type":"code","metadata":{"id":"yOP2frgimwRc","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aW4CJVXkrix","colab_type":"text"},"source":["### Missing values `age`"]},{"cell_type":"code","metadata":{"id":"i5RZx75G70oR","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"npdO5EFtmEkc","colab_type":"text"},"source":["### Missing values `embarked` and `embark_town`"]},{"cell_type":"code","metadata":{"id":"BlicX6zH8CCG","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M1UxeIVw8KPS","colab_type":"text"},"source":["## 3. Preparing data for modelling"]},{"cell_type":"code","metadata":{"id":"tXT_SuKD8XjH","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RjacQSxz92Fm","colab_type":"text"},"source":["#### `fare` from `float64` to `int64`"]},{"cell_type":"code","metadata":{"id":"HVPpCabf-AeA","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LHT49XaQ-Y0x","colab_type":"text"},"source":["#### `sex` to numeric\n"]},{"cell_type":"code","metadata":{"id":"TKKV0l8kBRy9","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdftyXGVBjgH","colab_type":"text"},"source":["#### `embarked` to numeric"]},{"cell_type":"code","metadata":{"id":"bl9r_c2FBmG3","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Liz3CN_jFIlx","colab_type":"text"},"source":["### `alone` from boolean to numeric"]},{"cell_type":"code","metadata":{"id":"csHjkj-lFOjD","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kL0eRYA8Gsk8","colab_type":"text"},"source":["### Getting dummies for categorical `deck` and `embark_town`"]},{"cell_type":"code","metadata":{"id":"kKE2V3ovGzpN","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"96U1wP4RPmwe","colab_type":"text"},"source":["### Multicollinearity"]},{"cell_type":"code","metadata":{"id":"LIKGoXpJPmPN","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FruBAfK3QvIW","colab_type":"text"},"source":["Areas of multi-collinearity::\n","\n","`embark_town_Queenston` and `embarked_Cherbourg` show a strong positive correlation with `embarked`, whistle `embark_town_Southampton` is strongly negatively correlated with `embarked`. This suggests that including `embark_town` only as a feature should be enough to control for the influence of place of embarkment.\n","\n","`deck_0` which is our `NaN` values, and `pclass` are perfectly positively correlated and negatively correlated with `fare`. This could mean different things. Perhaps is because deck numbers are correlated with ticket class and people without a ticket were all from certain class. Thus, dropping `deck_0` should be ok, as it is being taken into account by `pclass`. \n","\n","As expected, `sex` and `survived` also show strong positive correlation. \n","\n","Unsurprisingly, `fare` and `pclass` are strongly negatively correlated, so one will be dropped."]},{"cell_type":"markdown","metadata":{"id":"ZaFcepzGJnRs","colab_type":"text"},"source":["### Feature scaling"]},{"cell_type":"markdown","metadata":{"id":"TNtwDLvSLde1","colab_type":"text"},"source":["Finally, predictive features `X` and the target feature `y` can be separated, and `X` will be scaled with `StandardScaler` from `sklearn`."]},{"cell_type":"code","metadata":{"id":"jzYzfFE9MQ6F","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kf0EMEk1C-aW","colab_type":"text"},"source":["## 4. Building a Machine Learning Model"]},{"cell_type":"markdown","metadata":{"id":"ymRtpTkXOPk7","colab_type":"text"},"source":["### Random Forest"]},{"cell_type":"code","metadata":{"id":"zfsZSZs3DAqS","colab_type":"code","cellView":"form","colab":{}},"source":["# Your code goes here\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-5QRDKMoe6d","colab_type":"text"},"source":["## 5. Conclusion\n"]},{"cell_type":"markdown","metadata":{"id":"StIZFOdpoB4g","colab_type":"text"},"source":["As expected, `sex` and `age` are the main features by far, with a model accuracy of 79.37%, which could be improved by doing some hyper-parameter tunning.\n"]}]}